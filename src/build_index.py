from pathlib import Path
from itertools import groupby

from langchain_community.vectorstores import FAISS

from loaders import load_documents
from splitters import split_by_doc_type
from embeddings import get_embeddings

INDEX_DIR = "../data/index"
INDEX_NAME = "nav_faiss"  # æœ€ç»ˆä¼šç”Ÿæˆ data/index/nav_faiss ç›®å½•


def build_index():
    print("ğŸ” å¼€å§‹åŠ è½½æ–‡æ¡£...")
    docs = load_documents("../data/documents")
    print(f"âœ… åŠ è½½å®Œæˆï¼Œå…± {len(docs)} ä¸ªåŸå§‹chunk")

    print("\nâœ‚ï¸  å¼€å§‹è‡ªé€‚åº”åˆ‡åˆ†æ–‡æ¡£...")
    print("=" * 60)

    # æŒ‰æ–‡æ¡£åˆ†ç»„ï¼ˆæŒ‰sourceåˆ†ç»„ï¼Œä¿è¯åŒä¸€æ–‡æ¡£çš„chunksä¸€èµ·å¤„ç†ï¼‰
    docs_sorted = sorted(docs, key=lambda d: d.metadata.get('source', ''))
    all_splits = []

    for source, group in groupby(docs_sorted, key=lambda d: d.metadata['source']):
        group_docs = list(group)
        doc_type = group_docs[0].metadata.get('doc_type', 'doc_generic')
        file_type = group_docs[0].metadata.get('file_type', '.pdf')

        print(f"\nğŸ“„ {source}")
        print(f"  ç±»å‹: {doc_type} | æ ¼å¼: {file_type} | åŸå§‹chunks: {len(group_docs)}")

        # Excelæ–‡ä»¶å·²ç»åœ¨åŠ è½½æ—¶æŒ‰è¡Œåˆ‡åˆ†ï¼Œè·³è¿‡äºŒæ¬¡åˆ‡åˆ†
        if file_type in ['.xlsx', '.xls']:
            splits = group_docs
            print(f"  ğŸ“Š Excelæ–‡ä»¶ï¼Œè·³è¿‡åˆ‡åˆ†ï¼ˆå·²æŒ‰è¡Œåˆ‡åˆ†ï¼‰")
        else:
            # å…¶ä»–æ–‡ä»¶ç±»å‹è¿›è¡Œè‡ªé€‚åº”åˆ‡åˆ†
            splits = split_by_doc_type(group_docs)
            print(f"  âœ… åˆ‡åˆ†å: {len(splits)} chunks")

        all_splits.extend(splits)

    print("\n" + "=" * 60)
    print(f"âœ‚ï¸  æ€»åˆ‡åˆ†ç»“æœ: {len(all_splits)} chunks")

    # ç»Ÿè®¡ä¸åŒdoc_typeå’Œåˆ‡åˆ†ç­–ç•¥çš„åˆ†å¸ƒ
    print("\nğŸ“Š åˆ‡åˆ†ç»Ÿè®¡:")
    from collections import Counter
    doc_types = Counter(d.metadata.get('doc_type', 'unknown') for d in all_splits)
    for dtype, count in doc_types.most_common():
        print(f"  - {dtype}: {count} chunks")

    print("\nğŸ§  å‡†å¤‡ embedding æ¨¡å‹...")
    embeddings = get_embeddings()

    print("ğŸ“¦ æ­£åœ¨æ„å»º FAISS å‘é‡åº“...")
    vectorstore = FAISS.from_documents(all_splits, embeddings)
    save_path = Path(INDEX_DIR)
    save_path.mkdir(parents=True, exist_ok=True)

    vectorstore.save_local(str(save_path / INDEX_NAME))
    print(f"âœ… å‘é‡åº“å·²ä¿å­˜åˆ°: {save_path / INDEX_NAME}")


if __name__ == "__main__":
    build_index()
